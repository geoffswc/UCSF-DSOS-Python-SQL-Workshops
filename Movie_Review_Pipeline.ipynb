{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4N0OkqVmfRq"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from GitHub\n",
        "url = \"https://raw.githubusercontent.com/geoffswc/UCSF-DSOS-Python-SQL-Workshops/refs/heads/main/data/movie_reviews.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Rename columns so they match your notebookâ€™s expected names\n",
        "df = df.rename(columns={'text': 'review', 'review': 'label'})\n",
        "\n",
        "# Shuffle rows (to preserve same behavior as before)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Inspect\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "Y8pGEjHSmmTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "rWSCOJnKmz7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['review'], df['label'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "06tc57oZmr6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # for WordNet data\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "8kIeue5LnS77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "owat15UGqX_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_analyzer(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Split words\n",
        "    words = text.split()\n",
        "    # Lemmatize each word\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return [lemmatizer.lemmatize(word) for word in words]"
      ],
      "metadata": {
        "id": "GdyC3x9pnVz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(\n",
        "    analyzer=lemmatize_analyzer,\n",
        "    stop_words='english',\n",
        "    max_features=5000\n",
        ")\n"
      ],
      "metadata": {
        "id": "YmMBGJsUn6_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=41))\n",
        "])\n"
      ],
      "metadata": {
        "id": "4Z6p26YSoDv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = pipeline.named_steps['vectorizer']\n",
        "classifier = pipeline.named_steps['classifier']"
      ],
      "metadata": {
        "id": "b3_i03f1oHMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "W9-Iu5Qcpy-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "importances = classifier.feature_importances_\n",
        "\n",
        "df_features = pd.DataFrame({\n",
        "    'word': feature_names,\n",
        "    'importance': importances\n",
        "})"
      ],
      "metadata": {
        "id": "uGBT9MBKpeZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features"
      ],
      "metadata": {
        "id": "05gJFn9npjoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vec = vectorizer.transform(X_train)\n",
        "X_dense = X_train_vec.toarray()\n",
        "\n",
        "# Binary labels for convenience\n",
        "y_train_bin = (y_train == 'pos').astype(int)\n",
        "\n",
        "# Count per class\n",
        "count_positive = X_dense[y_train_bin==1].sum(axis=0)\n",
        "count_negative = X_dense[y_train_bin==0].sum(axis=0)\n",
        "\n",
        "# Total count across all documents\n",
        "total_count = X_dense.sum(axis=0)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "importances = classifier.feature_importances_\n",
        "\n",
        "df_features = pd.DataFrame({\n",
        "    'word': feature_names,\n",
        "    'importance': importances,\n",
        "    'count_positive': count_positive,\n",
        "    'count_negative': count_negative,\n",
        "    'total_count': total_count\n",
        "})\n",
        "\n",
        "# Sort by importance\n",
        "df_features_sorted = df_features.sort_values(by='importance', ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "qhYs8Fpwqeji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features_sorted.head(20)"
      ],
      "metadata": {
        "id": "udZn56xzrDv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features_sorted.tail(20)"
      ],
      "metadata": {
        "id": "gurMMfdYr6Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc:.2f}\")\n",
        "\n",
        "# Precision and Recall for the 'pos' class\n",
        "prec = precision_score(y_test, y_pred, pos_label=1)\n",
        "rec = recall_score(y_test, y_pred, pos_label=1)\n",
        "print(f\"Precision (pos): {prec:.2f}\")\n",
        "print(f\"Recall (pos): {rec:.2f}\")\n",
        "\n",
        "# Full classification report for all classes\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "SDbsFsN0r9vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Predict labels and probabilities\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_prob = pipeline.predict_proba(X_test)\n",
        "\n",
        "# 2. Extract probabilities for 'pos' and 'neg' explicitly\n",
        "# Make sure to match the correct column for each class\n",
        "class_order = pipeline.classes_  # e.g., ['neg', 'pos']\n",
        "prob_pos = y_prob[:, list(class_order).index(1)]\n",
        "prob_neg = y_prob[:, list(class_order).index(0)]\n",
        "\n",
        "# 3. Build the DataFrame\n",
        "df_reviews = pd.DataFrame({\n",
        "    'text': X_test,\n",
        "    'actual': y_test,\n",
        "    'predicted': y_pred,\n",
        "    'prob_pos': prob_pos,\n",
        "    'prob_neg': prob_neg\n",
        "})\n",
        "\n",
        "# 4. Display the first few rows\n",
        "df_reviews.head()"
      ],
      "metadata": {
        "id": "9kzLhrwiPiBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandasql"
      ],
      "metadata": {
        "id": "aoijIUU2RuLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandasql\n",
        "pysqldf = lambda q: pandasql.sqldf(q, globals())\n",
        "\n",
        "# Make sure df_reviews exists and has the columns: text, actual, predicted, prob_pos, prob_neg\n",
        "\n",
        "# SQL query:\n",
        "# 1. Filter where actual != predicted\n",
        "# 2. Compute the maximum of prob_pos and prob_neg as the model's confidence\n",
        "# 3. Sort descending by that confidence\n",
        "# 4. Limit to top 10\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    text,\n",
        "    actual,\n",
        "    predicted,\n",
        "    prob_pos,\n",
        "    prob_neg,\n",
        "    CASE\n",
        "        WHEN prob_pos > prob_neg THEN prob_pos\n",
        "        ELSE prob_neg\n",
        "    END AS pred_confidence,\n",
        "    CASE\n",
        "        WHEN actual = 'pos' AND predicted != 'pos' THEN 'false_negative'\n",
        "        WHEN actual != 'pos' AND predicted = 'pos' THEN 'false_positive'\n",
        "        ELSE 'other'\n",
        "    END AS error_type\n",
        "FROM df_reviews\n",
        "WHERE actual != predicted\n",
        "ORDER BY pred_confidence DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "top10_worst_sql = pysqldf(query)\n",
        "\n"
      ],
      "metadata": {
        "id": "vkDJ6PpPP1so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the result\n",
        "top10_worst_sql"
      ],
      "metadata": {
        "id": "TrT3an_JaN0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLeu-pcCRsjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}