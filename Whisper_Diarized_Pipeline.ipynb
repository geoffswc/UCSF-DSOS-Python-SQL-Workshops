{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3MfwQ9Zapqr"
      },
      "outputs": [],
      "source": [
        "# =====================\n",
        "# Install Packages\n",
        "# =====================\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q resemblyzer pydub scikit-learn pandas requests\n",
        "!sudo apt update && sudo apt install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxUzjxbSudoE"
      },
      "outputs": [],
      "source": [
        "# =====================\n",
        "# Imports\n",
        "# =====================\n",
        "import urllib.request\n",
        "import os\n",
        "import requests\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from resemblyzer.hparams import sampling_rate\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import whisper\n",
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# =====================\n",
        "# Helper function for robust downloading\n",
        "# =====================\n",
        "def download_video_robust(video_url, video_path):\n",
        "    if os.path.exists(video_path):\n",
        "        print(\"Video already downloaded, skipping.\")\n",
        "        return True\n",
        "\n",
        "    print(\"Downloading video...\")\n",
        "    try:\n",
        "        response = requests.get(video_url, stream=True)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        with open(video_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(\"Download complete!\")\n",
        "        return True\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        if os.path.exists(video_path):\n",
        "            os.remove(video_path)\n",
        "        return False\n",
        "\n",
        "# =====================\n",
        "# Pipeline function to process one video\n",
        "# =====================\n",
        "def process_video(video_url, video_id):\n",
        "    print(f\"\\nProcessing video {video_id} from {video_url}\")\n",
        "\n",
        "    video_path = f\"video_{video_id}.mp4\"\n",
        "    full_audio_path = f\"audio_{video_id}.wav\"\n",
        "    diarized_segments = []\n",
        "\n",
        "    # Download video\n",
        "    if not download_video_robust(video_url, video_path):\n",
        "        return []\n",
        "\n",
        "    # Extract full audio\n",
        "    print(\"Extracting full audio...\")\n",
        "    os.system(f\"ffmpeg -i {video_path} -ac 1 -ar 16000 -vn -y {full_audio_path}\")\n",
        "\n",
        "    # Load and split audio into chunks\n",
        "    print(\"Splitting audio into 5-minute chunks...\")\n",
        "    audio = AudioSegment.from_wav(full_audio_path)\n",
        "    chunk_length_ms = 5 * 60 * 1000 # 5 minutes in milliseconds\n",
        "\n",
        "    num_speakers = 2\n",
        "    model = whisper.load_model(\"small\")\n",
        "    encoder = VoiceEncoder()\n",
        "\n",
        "    for i in range(0, len(audio), chunk_length_ms):\n",
        "        start_time_offset = i / 1000.0  # Time offset in seconds\n",
        "        chunk = audio[i:i + chunk_length_ms]\n",
        "        chunk_path = f\"chunk_{video_id}_{i}.wav\"\n",
        "        chunk.export(chunk_path, format=\"wav\")\n",
        "        print(f\"Processing chunk {i/chunk_length_ms + 1} at offset {start_time_offset:.2f}s...\")\n",
        "\n",
        "        # Load chunk for embeddings\n",
        "        wav = preprocess_wav(chunk_path)\n",
        "        chunk_size = int(0.75 * sampling_rate)\n",
        "        step_size = int(0.375 * sampling_rate)\n",
        "        embeddings, timestamps = [], []\n",
        "\n",
        "        if len(wav) < chunk_size:\n",
        "            print(\"Chunk too short for embeddings, skipping.\")\n",
        "            os.remove(chunk_path)\n",
        "            continue\n",
        "\n",
        "        for start_idx in range(0, len(wav) - chunk_size + 1, step_size):\n",
        "            emb = encoder.embed_utterance(wav[start_idx : start_idx + chunk_size])\n",
        "            embeddings.append(emb)\n",
        "            timestamps.append(start_idx / sampling_rate)\n",
        "\n",
        "        embeddings = np.vstack(embeddings)\n",
        "        kmeans = KMeans(n_clusters=num_speakers, random_state=0).fit(embeddings)\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        # Transcribe the chunk\n",
        "        result = model.transcribe(chunk_path, word_timestamps=True, verbose=False)\n",
        "        segments = result['segments']\n",
        "\n",
        "        # Assign speaker labels and build list of dicts\n",
        "        for seg in segments:\n",
        "            mid = (seg['start'] + seg['end']) / 2\n",
        "            closest_idx = np.argmin(np.abs(np.array(timestamps) - mid))\n",
        "            speaker = f\"Speaker {labels[closest_idx]}\"\n",
        "\n",
        "            diarized_segments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_url\": video_url,\n",
        "                \"start\": start_time_offset + seg['start'],\n",
        "                \"end\": start_time_offset + seg['end'],\n",
        "                \"speaker\": speaker,\n",
        "                \"text\": seg['text'].strip()\n",
        "            })\n",
        "\n",
        "        os.remove(chunk_path) # Clean up chunk file\n",
        "\n",
        "    os.remove(full_audio_path)\n",
        "    print(\"All chunks processed.\")\n",
        "    return diarized_segments\n",
        "\n",
        "# =====================\n",
        "# Main execution: process multiple videos and save results\n",
        "# =====================\n",
        "video_urls = [\n",
        "  'https://archive.org/download/tobacco_qno71d00/VTS_01_1_512kb.mp4'\n",
        "]\n",
        "\n",
        "# Define the Google Drive directory\n",
        "output_dir = \"/content/gdrive/MyDrive/DiarizedTranscripts-Small\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for idx, url in enumerate(video_urls, start=1):\n",
        "\n",
        "    print(\"processing\", url)\n",
        "\n",
        "    #i += 1\n",
        "    #if i > 101:\n",
        "    #  print(\"processed 101, let's take a break\")\n",
        "    #  break\n",
        "\n",
        "    video_name = url.split(\"/download/\")[1].split(\"/\")\n",
        "    video_id = video_name[0] + '_' + video_name[1]\n",
        "    file_name = f\"video_{video_id}_transcript.txt\"\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "    # Skip if the transcript already exists\n",
        "    if os.path.exists(file_path):\n",
        "        # don't count this against the amount we've already processed\n",
        "        i -= 1\n",
        "        print(f\"Transcript for video {video_id} already exists, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Process the video\n",
        "    segments = process_video(url, video_id)\n",
        "\n",
        "    # Save the segments to a text file\n",
        "    with open(file_path, \"w\") as f:\n",
        "        for seg in segments:\n",
        "            f.write(f\"[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['speaker']}: {seg['text']}\\n\")\n",
        "\n",
        "    print(f\"\\nTranscript for video {video_id} saved to {file_path}\")\n",
        "\n",
        "    # Delete the downloaded video file to free local disk space\n",
        "    video_path = f\"video_{video_id}.mp4\"\n",
        "    if os.path.exists(video_path):\n",
        "        os.remove(video_path)\n",
        "        print(f\"Deleted {video_path} from local storage.\")\n",
        "\n",
        "print(\"\\nAll processing complete. Transcripts are available in your Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JWrALZK8ugno"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GtklfnVzVEtd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}